{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Leave commented out if already done\n# pip install Pillow\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nfrom PIL import Image\nimport time\nimport os\nfrom PIL import Image\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:16:17.150572Z","iopub.execute_input":"2022-12-15T00:16:17.151019Z","iopub.status.idle":"2022-12-15T00:16:24.519642Z","shell.execute_reply.started":"2022-12-15T00:16:17.150919Z","shell.execute_reply":"2022-12-15T00:16:24.518560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [176,208]               # input image dimensions                                              (176,208)\nBATCH_SIZE = 5000\ntest_split_percent = .1       # % of total data for testing                                         .1\nvalidation_split_percent = .2 # % of total data for validation                                      .2\nzoom = [.99,1.01]             # zoom range (for a fixed zoom put the same value in both parameters)[.99,1.01]\nbright_range = [.8,1.2]       # brightness range                                                    [.8,1.2] \nlayers_unlocked = True        # unlock the imported pre-training layers?                            False  \nlr = 0.01                   # learning rate for optimizer                                         0.0001\nbatch = 20                    # batch size for model fitting                                        20\nEPOCHS = 100                      # number of epochs to run                                             50\n#momentum = .9                 # momentum of SGD                                                     .9","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:16:24.522865Z","iopub.execute_input":"2022-12-15T00:16:24.524382Z","iopub.status.idle":"2022-12-15T00:16:24.530898Z","shell.execute_reply.started":"2022-12-15T00:16:24.524339Z","shell.execute_reply":"2022-12-15T00:16:24.529868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# introduced zoom, blew up the image of the brain itself, and brightness range to adjust for different brightness\ntrain_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,fill_mode='constant',cval=0,\n                                                           brightness_range=bright_range,zoom_range=zoom,\n                                                           data_format='channels_last',zca_whitening=False)\n\ntrain_data_gen = train_dr.flow_from_directory(directory=\"/kaggle/input/dataset-alzheimer/Alzheimer_s Dataset/train/\",target_size=IMAGE_SIZE,\n                                              batch_size=BATCH_SIZE)\n\n# Change to zoom = [1,1] to use normal test data\ntest_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,fill_mode='constant',cval=0,zoom_range=[1,1],\n                                                          data_format='channels_last') \ntest_data_gen = test_dr.flow_from_directory(directory=\"/kaggle/input/dataset-alzheimer/Alzheimer_s Dataset/test\",target_size=IMAGE_SIZE,batch_size=BATCH_SIZE,\n                                           shuffle = False) # test data should not be shuffle","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:16:24.532260Z","iopub.execute_input":"2022-12-15T00:16:24.532936Z","iopub.status.idle":"2022-12-15T00:16:26.353933Z","shell.execute_reply.started":"2022-12-15T00:16:24.532892Z","shell.execute_reply":"2022-12-15T00:16:26.352832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data,train_labels =  train_data_gen.next()\ntest_data,test_labels = test_data_gen.next()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:16:26.356149Z","iopub.execute_input":"2022-12-15T00:16:26.356486Z","iopub.status.idle":"2022-12-15T00:17:27.062794Z","shell.execute_reply.started":"2022-12-15T00:16:26.356457Z","shell.execute_reply":"2022-12-15T00:17:27.061603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cocatenate arrays, combining all data\ntotal_data = np.concatenate((train_data,test_data))\ntotal_labels = np.concatenate((train_labels,test_labels))\nprint(total_data.shape)\nprint(total_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:27.066243Z","iopub.execute_input":"2022-12-15T00:17:27.068582Z","iopub.status.idle":"2022-12-15T00:17:28.053624Z","shell.execute_reply.started":"2022-12-15T00:17:27.068538Z","shell.execute_reply":"2022-12-15T00:17:28.052647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_split = test_split_percent+validation_split_percent\ntest_val_split = test_split_percent/initial_split\n\n# split into training and (test + validation)\ntrain_data, test_val_data, train_labels, test_val_labels = train_test_split(total_data,total_labels,\n                                                                            test_size=initial_split)\n\n# split (test + validation) into test and validation sets\ntest_data, val_data, test_labels, val_labels = train_test_split(test_val_data,test_val_labels,\n                                                                test_size=test_val_split)\n\nprint('train: ',train_data.shape)\nprint('validation',val_data.shape)\nprint('test',test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:28.054773Z","iopub.execute_input":"2022-12-15T00:17:28.055064Z","iopub.status.idle":"2022-12-15T00:17:29.296667Z","shell.execute_reply.started":"2022-12-15T00:17:28.055038Z","shell.execute_reply":"2022-12-15T00:17:29.295469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(train_labels.shape)\nprint(val_data.shape)\nprint(val_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:29.298553Z","iopub.execute_input":"2022-12-15T00:17:29.299800Z","iopub.status.idle":"2022-12-15T00:17:29.308026Z","shell.execute_reply.started":"2022-12-15T00:17:29.299758Z","shell.execute_reply":"2022-12-15T00:17:29.306546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check some images\nplt.subplot(221)\nplt.imshow(train_data[1,:,:,:])\nplt.subplot(222)\nplt.imshow(train_data[2,:,:,:])\nplt.subplot(223)\nplt.imshow(val_data[3,:,:,:])\nplt.subplot(224)\nplt.imshow(val_data[4,:,:,:])\nplt.show()\nplt.subplot(221)\nplt.imshow(test_data[5,:,:,:])\nplt.subplot(222)\nplt.imshow(test_data[154,:,:,:])","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:29.312101Z","iopub.execute_input":"2022-12-15T00:17:29.313717Z","iopub.status.idle":"2022-12-15T00:17:30.162151Z","shell.execute_reply.started":"2022-12-15T00:17:29.313658Z","shell.execute_reply":"2022-12-15T00:17:30.161227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess the images in the same manner as those trained on original model\n#train_data = preprocess_input(train_data)\n#val_data = preprocess_input(val_data)\n#test_data = preprocess_input(test_data)\nprint(np.amax(train_data))\nprint(np.amin(train_data))\nprint(np.amax(val_data))\nprint(np.amin(val_data))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:30.163692Z","iopub.execute_input":"2022-12-15T00:17:30.164077Z","iopub.status.idle":"2022-12-15T00:17:30.573284Z","shell.execute_reply.started":"2022-12-15T00:17:30.164041Z","shell.execute_reply":"2022-12-15T00:17:30.572114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check image channels\nplt.subplot(141)\nplt.imshow(train_data[3,:,:,0])\nplt.subplot(142)\nplt.imshow(train_data[3,:,:,1])\nplt.subplot(143)\nplt.imshow(train_data[3,:,:,2])\nplt.subplot(144)\nplt.imshow(train_data[3,:,:,:])","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:30.577207Z","iopub.execute_input":"2022-12-15T00:17:30.577506Z","iopub.status.idle":"2022-12-15T00:17:30.980555Z","shell.execute_reply.started":"2022-12-15T00:17:30.577479Z","shell.execute_reply":"2022-12-15T00:17:30.979587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        #tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', strides=2, padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ])\n    \n    return block","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:30.982154Z","iopub.execute_input":"2022-12-15T00:17:30.982579Z","iopub.status.idle":"2022-12-15T00:17:30.988233Z","shell.execute_reply.started":"2022-12-15T00:17:30.982551Z","shell.execute_reply":"2022-12-15T00:17:30.987218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:30.990070Z","iopub.execute_input":"2022-12-15T00:17:30.990743Z","iopub.status.idle":"2022-12-15T00:17:31.001099Z","shell.execute_reply.started":"2022-12-15T00:17:30.990681Z","shell.execute_reply":"2022-12-15T00:17:31.000099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        #tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(4, activation='softmax')\n    ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:31.003497Z","iopub.execute_input":"2022-12-15T00:17:31.004204Z","iopub.status.idle":"2022-12-15T00:17:31.012560Z","shell.execute_reply.started":"2022-12-15T00:17:31.004112Z","shell.execute_reply":"2022-12-15T00:17:31.011527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [tf.keras.metrics.BinaryAccuracy(name='accuracy'),tf.keras.metrics.Precision(name='precision'),\n               tf.keras.metrics.Recall(name='recall'),tf.keras.metrics.AUC(name='auc')]\n\n    \n    model.compile(\n        optimizer='adam',\n        loss=tf.losses.CategoricalCrossentropy(),\n        metrics=METRICS\n    )","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:31.014121Z","iopub.execute_input":"2022-12-15T00:17:31.014531Z","iopub.status.idle":"2022-12-15T00:17:34.221264Z","shell.execute_reply.started":"2022-12-15T00:17:31.014498Z","shell.execute_reply":"2022-12-15T00:17:34.220289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch / s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\n#checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\", save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:34.223715Z","iopub.execute_input":"2022-12-15T00:17:34.224065Z","iopub.status.idle":"2022-12-15T00:17:34.232445Z","shell.execute_reply.started":"2022-12-15T00:17:34.224030Z","shell.execute_reply":"2022-12-15T00:17:34.230245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(train_data,train_labels,validation_data=(val_data,val_labels),\n                             epochs=EPOCHS,batch_size=batch, shuffle=True) #changed batch size from 15","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:17:34.234077Z","iopub.execute_input":"2022-12-15T00:17:34.235265Z","iopub.status.idle":"2022-12-15T00:46:02.446260Z","shell.execute_reply.started":"2022-12-15T00:17:34.235223Z","shell.execute_reply":"2022-12-15T00:46:02.445207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_data, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:46:02.448413Z","iopub.execute_input":"2022-12-15T00:46:02.448787Z","iopub.status.idle":"2022-12-15T00:46:04.388793Z","shell.execute_reply.started":"2022-12-15T00:46:02.448753Z","shell.execute_reply":"2022-12-15T00:46:04.387828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import load_model\n\nmodel.save('/kaggle/working/model')\n\npretrained_model = load_model('/kaggle/working/model/')\n\n#Check its architecture\nplot_model(pretrained_model, to_file='/kaggle/working/model/' + \"model_plot.png\", show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:49:00.641918Z","iopub.execute_input":"2022-12-15T00:49:00.642268Z","iopub.status.idle":"2022-12-15T00:49:13.064487Z","shell.execute_reply.started":"2022-12-15T00:49:00.642237Z","shell.execute_reply":"2022-12-15T00:49:13.063320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T00:46:04.391394Z","iopub.execute_input":"2022-12-15T00:46:04.391965Z","iopub.status.idle":"2022-12-15T00:46:04.401549Z","shell.execute_reply.started":"2022-12-15T00:46:04.391928Z","shell.execute_reply":"2022-12-15T00:46:04.399281Z"},"trusted":true},"execution_count":null,"outputs":[]}]}